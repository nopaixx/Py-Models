{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": " \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n\nimport os\nprint(os.listdir(\"../input\"))\n\n",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['embeddings', 'train.csv', 'sample_submission.csv', 'test.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4c14dd25258b21622152c0731ddaac6be949faf5"
      },
      "cell_type": "code",
      "source": "train_df=pd.read_csv('../input/train.csv')\ntest_df=pd.read_csv('../input/test.csv')",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b315c30fba221078a07539f8eecac6ca329b8918"
      },
      "cell_type": "code",
      "source": "\ntrain_df['labels_text'] = '__label__' + train_df.target.map(str)\ntrain_df.labels_text = train_df.labels_text.str.cat(train_df.question_text, sep=' ')\n\n# Write training data to a file as required by fasttext\ntraining_file = open('train.txt','w')\ntraining_file.writelines(train_df.labels_text + '\\n')\ntraining_file.close()\n\n\nprint(os.listdir(\"./\"))",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['train.txt', '__notebook_source__.ipynb', '.ipynb_checkpoints']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0335373a6f844233f138676e1773e3c7fa373e90"
      },
      "cell_type": "code",
      "source": "import fastText as ft\nimport pandas as pd\nimport numpy as np \nimport re\nimport fastText as ft\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score\nfrom collections import Counter\n# Function to do K-fold CV across different fasttext parameter values\ndef tune(Y, X, YX, k, lr, wordNgrams, epoch):\n    # Record results\n    results = []\n    for lr_val in lr:\n        for wordNgrams_val in wordNgrams:\n            for epoch_val in epoch:  \n                # K-fold CV\n                kf = KFold(n_splits=k, shuffle=True)\n                fold_results = []\n                # For each fold\n                for train_index, test_index in kf.split(X):\n                    # Write the training data for this CV fold\n                    training_file = open('train_cv.txt','w')\n                    training_file.writelines(YX[train_index] + '\\n')\n                    training_file.close()\n                    # Fit model for this set of parameter values\n                    model = ft.FastText.train_supervised('train_cv.txt',\n                                          lr=lr_val,\n                                          wordNgrams=wordNgrams_val,\n                                          epoch=epoch_val)\n                    # Predict the holdout sample\n                    pred = model.predict(X[test_index].tolist())\n                    pred = pd.Series(pred[0]).apply(lambda x: re.sub('__label__', '', x[0]))\n                    # Compute accuracy for this CV fold\n                    fold_results.append(accuracy_score(Y[test_index], pred.values))\n                # Compute mean accuracy across 10 folds\n                mean_acc = pd.Series(fold_results).mean()\n                print([lr_val, wordNgrams_val, epoch_val, mean_acc])\n    # Add current parameter values and mean accuracy to results table\n    results.append([lr_val, wordNgrams_val, epoch_val, mean_acc])         \n    # Return as a DataFrame \n    results = pd.DataFrame(results)\n    results.columns = ['lr','wordNgrams','epoch','mean_acc']\n    return(results)\n# Tune parameters using 10-fold CV\n#results = tune(Y = train_df.target.map(str),\n#               X = train_df.question_text,\n#               YX = train_df.labels_text,\n#               k = 10, \n#               lr = [0.05, 0.1, 0.2],\n#               wordNgrams = [1,2,3],\n#               epoch = [15,17,20]\n#              )\n# Train final classifiers\nclassifier1 = ft.FastText.train_supervised('train.txt', lr=0.1, wordNgrams=1, epoch=500)\nclassifier2 = ft.FastText.train_supervised('train.txt', lr=0.1, wordNgrams=2, epoch=500)\nclassifier3 = ft.FastText.train_supervised('train.txt', lr=0.1, wordNgrams=3, epoch=500)\nprint(\"DONE\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "99e8bda38d7dc20df8422a5f0587b90886e23b50"
      },
      "cell_type": "code",
      "source": "mlist=test_df[\"question_text\"].map(lambda s: s.strip()).tolist()\n#print(test_df[\"question_text\"])\n\nmlist",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2dcf24799a20d4b286d902a6918906538c2f950a"
      },
      "cell_type": "code",
      "source": "\npredictions1 = classifier1.predict(mlist)\npredictions2 = classifier2.predict(mlist)\npredictions3 = classifier3.predict(mlist)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "27864c07b9991372695b1a5800a4a16500e1af2d"
      },
      "cell_type": "code",
      "source": "#print(predictions1)\n#print(predictions2)\n#print(predictions3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cc5439034f44fa1a619439b83afadccabb50f496"
      },
      "cell_type": "code",
      "source": "# Combine predictions\nmajority_vote = np.array([])\nfor i in range(len(predictions1[0])):\n    majority_vote = np.append(majority_vote, Counter([predictions1[0][i][0],\n                                                   predictions2[0][i][0],\n                                                   predictions3[0][i][0]]).most_common(1)[0][0])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d85b108c02f1c80fb20f154687e0a4d561c5521a"
      },
      "cell_type": "code",
      "source": "\nimport os\nimport glob\n\nimport os, shutil\nfolder = './'\nfor the_file in os.listdir(folder):\n    file_path = os.path.join(folder, the_file)\n    try:\n        if os.path.isfile(file_path):\n            os.unlink(file_path)\n        #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n    except Exception as e:\n        print(e)\n\nprint(os.listdir(\"./\"))    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ac81e66ac720a01555db501859055a7e99c2d02b"
      },
      "cell_type": "code",
      "source": "\n\nsubmit = pd.DataFrame({'qid': test_df[\"qid\"].values, \n                       'prediction': pd.Series(majority_vote)})\nsubmit.prediction = submit.prediction.apply(lambda x: re.sub('__label__', '', x))\nsubmit.to_csv('submission.csv', index=False)\nsubmit",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}