{
  "cells": [
    {
      "metadata": {
        "scrolled": true,
        "_cell_guid": "dbf2ff22-712b-4fc2-8687-99caa9bf07d8",
        "_uuid": "f57e59e8589cb94001d8673fb737a4e0d96852bd",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n\n# Any results you write to the current directory are saved as output.\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom os.path import join as opj\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport pylab\nplt.rcParams['figure.figsize'] = 10, 10\n%matplotlib inline\n#import h2o\nfrom h2o.estimators.deeplearning import H2OAutoEncoderEstimator, H2ODeepLearningEstimator\n#h2o.init()\nimport json \nimport pandas as pd \nfrom pandas.io.json import json_normalize #package for flattening json in pandas df\n#load json object\n#with open('../input/train.json') as f:\n #   d = json.load(f)\n\n#lets put the data into a pandas df\n#clicking on raw_nyc_phil.json under \"Input Files\"\n#tells us parent node is 'programs'\n#nycphil = json_normalize(d['band_1'])\n#nycphil.head(3)\n#print(d)\ntrain = pd.read_json(\"../input/train.json\")\ntest = pd.read_json(\"../input/test.json\")\n\n#h_band_1=h2o.H2OFrame(train[\"band_1\"].values)\n#h_band_2=h2o.H2OFrame(train[\"band_2\"].values)\n#t_band_1=h2o.H2OFrame(test[\"band_1\"].values)\n#t_band_2=h2o.H2OFrame(test[\"band_2\"].values)\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5292632717f11cd01c135dfabfd3cda9318cc639",
        "_cell_guid": "829bf7db-fab1-4a2d-9562-0a37c6390d2a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Generate the training data\n#Create 3 bands having HH, HV and avg of both\nX_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\nX_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n\n#X_train = np.concatenate([X_band_2[:, :, :, np.newaxis]],axis=-1)\n#X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis]],axis=-1)\n                          \nX_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "fb15bc53-becc-4e87-88ce-3bc99d45358d",
        "_uuid": "7a68a94f8c617209dfe56a58e291193e963d0f62",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Import Keras.\nfrom matplotlib import pyplot\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, Dense, Dropout, Input, Flatten, Activation\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras import initializers\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras.optimizers import SGD",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "119488d60b82fb746fe6b10fc7b7c989a2042b96",
        "_cell_guid": "e8a1e002-9854-4f28-8e0d-a508f29e2197",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#MODEL V2\nimport keras.backend as K\ndef mean_pred(y_true, y_pred):\n    return K.mean(y_pred)\n#define our model\ndef getModel():\n    #Building the model\n    gmodel = Sequential()\n    gmodel.add(Conv2D(20, (3, 3), input_shape=(75, 75,2)))\n    gmodel.add(Activation('relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2)))\n    gmodel.add(Dropout(0.1))\n    \n    gmodel.add(Conv2D(40, (3, 3)))\n    gmodel.add(Activation('relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2)))\n    gmodel.add(Dropout(0.1))    \n    \n    gmodel.add(Conv2D(20, (3, 3)))\n    gmodel.add(Activation('relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2)))\n    gmodel.add(Dropout(0.1))    \n    \n    gmodel.add(Conv2D(20, (3, 3)))\n    gmodel.add(Activation('relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2)))\n    gmodel.add(Dropout(0.1))    \n    \n    gmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n    gmodel.add(Dense(640))\n    gmodel.add(Activation('relu'))\n    gmodel.add(Dropout(0.5))\n    \n    gmodel.add(Dense(1))\n    gmodel.add(Activation('sigmoid'))\n    \n    gmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n    gmodel.summary()    \n    return gmodel\n\ndef get_callbacks(filepath, patience=2):\n    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [es, msave]\nfile_path = \".model_weights.hdf5\"\ncallbacks = get_callbacks(filepath=file_path, patience=10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fd7e0e437b946908cd62271bedf2500ab0e5f75f",
        "_cell_guid": "f737af2f-2f20-4b25-ba68-da86cd83dcd5",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#MODEL V3\n#define our model\ndef getModelV3():\n    #Building the model\n    gmodel = Sequential()\n    gmodel.add(Conv2D(120, (3, 3), input_shape=(75, 75,3)))\n    gmodel.add(Activation('relu'))\n    gmodel.add(Conv2D(40, (3, 3)))\n    gmodel.add(Activation('relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2)))\n   # gmodel.add(Dropout(0.1))\n    \n    gmodel.add(Conv2D(40, (3, 3)))\n    gmodel.add(Activation('relu'))\n    gmodel.add(Conv2D(40, (3, 3)))\n    gmodel.add(Activation('relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2)))\n    #gmodel.add(Dropout(0.1))    \n    \n    gmodel.add(Conv2D(20, (3, 3)))\n    gmodel.add(Activation('relu'))\n    gmodel.add(Conv2D(40, (3, 3)))\n    gmodel.add(Activation('relu'))\n    gmodel.add(Conv2D(40, (3, 3)))\n    gmodel.add(Activation('relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2)))\n    #gmodel.add(Dropout(0.1))    \n    \n    gmodel.add(Conv2D(20, (3, 3)))\n    gmodel.add(Activation('relu'))\n    gmodel.add(Conv2D(40, (3, 3)))\n    gmodel.add(Activation('relu'))\n    gmodel.add(Conv2D(40, (3, 3)))\n    gmodel.add(Activation('relu'))\n    gmodel.add(MaxPooling2D(pool_size=(2, 2)))\n   # gmodel.add(Dropout(0.1))    \n    \n    gmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n    gmodel.add(Dense(640))\n    gmodel.add(Activation('relu'))\n  #  gmodel.add(Dropout(0.5))\n    \n    gmodel.add(Dense(1))\n    gmodel.add(Activation('sigmoid'))\n    \n    gmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n    gmodel.summary()    \n    return gmodel\n\ndef get_callbacks(filepath, patience=2):\n    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [es, msave]\nfile_path = \".model_weights.hdf5\"\ncallbacks = get_callbacks(filepath=file_path, patience=10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f3a4a55713ab218e6092476705cc7b4b6d3dd280",
        "_cell_guid": "65e1ed66-f1f7-49fc-af63-5abdc9391aba",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "def VGG_16(weights_path=None):\n    model = Sequential()\n    model.add(ZeroPadding2D((1,1),input_shape=(75,75,3)))\n    model.add(Conv2D(64, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(64, 3, 3, activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(128, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(128, 3, 3, activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(128, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(128, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(128, 3, 3, activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(512, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(512, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(512, 3, 3, activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(512, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(512, 3, 3, activation='relu'))\n    model.add(ZeroPadding2D((1,1)))\n    model.add(Conv2D(512, 3, 3, activation='relu'))\n    model.add(MaxPooling2D((2,2), strides=(2,2)))\n\n    model.add(Flatten())\n    model.add(Dense(4000, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(4000, activation='relu'))\n    model.add(Dropout(0.5))\n    #model.add(Dense(1000, activation='softmax'))\n    model.add(Dense(1, activation='sigmoid'))\n    sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n    model.compile(optimizer=\"adamax\", loss='binary_crossentropy',metrics=['accuracy'])\n    if weights_path:\n        model.load_weights(weights_path)\n\n    return model\n\ndef get_callbacks(filepath, patience=2):\n    es = EarlyStopping('loss', patience=patience, mode=\"min\")\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [es, msave]\nfile_path = \".model_weights.hdf5\"\ncallbacks = get_callbacks(filepath=file_path, patience=5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1d690d4a-09ca-417c-8090-2aa417c514dd",
        "_uuid": "a883659e53709da950d04a4e5349c66d77a9422f",
        "trusted": false
      },
      "cell_type": "code",
      "source": "target_train=train['is_iceberg']\n#X_train2 = X_train2.reshape(X_train.shape[0],15, 15,3)\nX_train_cv, X_valid, y_train_cv, y_valid = train_test_split(X_train, target_train, random_state=1, train_size=0.99)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ca383bc03b8e5fb15c714fb2419842acd9b3c4bd",
        "_cell_guid": "b1bd3834-8a1a-4d5d-8540-77b5556b032f",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.image import ImageDataGenerator\ngen_images = ImageDataGenerator(  \n  horizontal_flip = True,\n  vertical_flip = True,\n  width_shift_range = 0.30,\n  height_shift_range = 0.30,\n  zoom_range = 0.1,\n  rotation_range = 20\n  )\n# prepare data augmentation configuration\ntrain_datagen = ImageDataGenerator(\n   horizontal_flip = True,\n  vertical_flip = True,\n  width_shift_range = 0.30,\n  height_shift_range = 0.30,\n  #zoom_range = 0.1,\n  rotation_range = 180\n)\n\n\ntest_datagen = ImageDataGenerator(\n  horizontal_flip = True,\n  vertical_flip = True,\n  width_shift_range = 0.30,\n  height_shift_range = 0.30,\n  #zoom_range = 0.1,\n  rotation_range = 180\n)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d6bb750a-e882-4429-ad23-4392389f427f",
        "_uuid": "4e6dab11165b7d9515eb32b698851b260f0d941f",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Without denoising, core features.\n#befor submit this we can try to h2o autoencodes?\nimport os\ngmodel=VGG_16(None)\nbatch_size=200\ntrain_generator = train_datagen.flow(X_train_cv,y_train_cv,batch_size=batch_size)\n\nvalidation_generator = test_datagen.flow(X_valid,y_valid,batch_size=batch_size)\n\n# fine-tune the model\ngmodel.fit_generator(\n        train_generator,\n        steps_per_epoch=X_train_cv.shape[0] // batch_size,\n        epochs=50,\n        verbose=1,\n       # validation_data=validation_generator,\n         callbacks=get_callbacks(filepath=file_path, patience=5))\n        #validation_steps=nb_validation_samples // batch_size)\n    \n#gmodel.summary()  \n#gmodel.fit(X_train_cv, y_train_cv,\n #         batch_size=32,\n  #        epochs=50,\n   #       verbose=1,\n    #      validation_data=(X_valid, y_valid),\n     #     callbacks=callbacks)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0fa65f37d198cd6301376f179d9de0ccc1d40db3",
        "_cell_guid": "079f0a8d-d2a5-4154-b37f-b425333e4ada",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(\"h\")\ngmodel.load_weights(filepath=file_path)\nscore = gmodel.evaluate(X_valid, y_valid, verbose=1)\n#print('Test loss:', score[0])\nprint('Test accuracy:', score)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "27f021784da863a2ad960a96b9c7394f25521802",
        "_cell_guid": "7cae1458-a566-4714-8b80-0b23fe88509c",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\nX_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\nX_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n                          , X_band_test_2[:, :, :, np.newaxis]\n                         , ((X_band_test_1+X_band_test_2)/2)[:, :, :, np.newaxis]], axis=-1)\npredicted_test=gmodel.predict_proba(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b34412c33fe8250df3285867d9a13e4bd08e8c12",
        "_cell_guid": "da3618f6-6e0a-475c-a390-7e17f5406c1a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "submission = pd.DataFrame()\nsubmission['id']=test['id']\nsubmission['is_iceberg']=predicted_test.reshape((predicted_test.shape[0]))\nsubmission.to_csv('sub.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6b12edd6014eda6aa87f163cfb0ca2bd88baae72",
        "_cell_guid": "0620c1f0-f60d-4a76-8990-90c679286469",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# build a classifier model to put on top of the convolutional model\ntop_model = Sequential()\n#top_model.add(Flatten(input_shape=model.output_shape[1:]))\ntop_model.add(Dense(256, activation='relu',input_shape=gmodel.output_shape[1:]))\n#top_model.add(Flatten(Input(gmodel.output_shape[1:])))\n#top_model.add()\n#top_model.add(Dense(256, activation='relu'))\ntop_model.add(Dropout(0.5))\ntop_model.add(Dense(1, activation='sigmoid'))\n\n# note that it is necessary to start with a fully-trained\n# classifier, including the top classifier,\n# in order to successfully do fine-tuning\n\n\n# add the model on top of the convolutional base\ngmodel=gmodel=VGG_16(file_path)\ngmodel.load_weights(file_path)\ngmodel.add(top_model)\n\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e253b0ab84618040a4fabcd9a00275eaee75d13c",
        "_cell_guid": "717d37b1-d9bf-4f42-9680-1f00cd054f06",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# set the first 25 layers (up to the last conv block)\n# to non-trainable (weights will not be updated)\nfor layer in gmodel.layers[:25]:\n    layer.trainable = False\n\n# compile the model with a SGD/momentum optimizer\n# and a very slow learning rate.\ngmodel.compile(loss='binary_crossentropy',\n              optimizer=SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8158350d9c66b9e593f50184f7f431d7d8480d12",
        "_cell_guid": "a3232ad9-8987-4f0e-aaae-4d184ab2642f",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "\n# featurewise_center = TRUE,\n  # featurewise_std_normalization = TRUE,\n#gmodel.fit(X_train_cv, y_train_cv,\n #         batch_size=32,\n  #        epochs=50,\n   #       verbose=1,\n    #      validation_data=(X_valid, y_valid),\n#          callbacks=callbacks\ntrain_generator = train_datagen.flow(X_train_cv,y_train_cv,batch_size=1000,seed=54321)\n\nvalidation_generator = test_datagen.flow(X_valid,y_valid,batch_size=400,seed=54321)\n\n# fine-tune the model\ngmodel.fit_generator(\n        train_generator,\n        #steps_per_epoch=nb_train_samples // batch_size,\n        epochs=50,\n        verbose=1,\n        validation_data=validation_generator)\n        #validation_steps=nb_validation_samples // batch_size)\n\n\n#gmodel.fit_generator(\n  #flow_images_from_data(x = X_train_cv, y = y_train_cv,generator = gen_images, seed = 123),     \n   # epochs = epochs,\n   #  verbose=1,\n  #     validation_data=(X_valid, y_valid),\n #     callbacks = callbacks\n#)\n\n#flow_images_from_data(x = train[[1]], y = train[[3]],generator = gen_images,\n #    batch_size=batch_size, seed = 123)\n",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "file_extension": ".py",
      "name": "python",
      "nbconvert_exporter": "python",
      "mimetype": "text/x-python",
      "version": "3.6.4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}